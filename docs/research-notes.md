# Notes and thoughts on current research

A document to maintain a running list of thoughts regarding the HMA clustering project.

## 11 Sept 2020

Clustering algorithms

- Simplest and most straightforward would be k-mean clustering (but there are likely better approaches)
- Another option with easy implentation (scikit-learn) is Gaussian mixture models, introduced (along with other clustering techniques) [here](https://machinelearningmastery.com/clustering-algorithms-with-python/)
- Also possible to perform clustering analysis using Gaussian processes (example [here](http://staging.csml.ucl.ac.uk/archive/talks/41e4e55330421a6e230d0ea2b89440ea/Paper_16.pdf))
- Additional useful links for Gaussian process clustering are [here](https://www.ki.tu-berlin.de/fileadmin/fg135/publikationen/Yang_2014_GPC.pdf) and [here](https://github.com/titicaca/GP-Clustering)
- Additional useful links for Gaussian mixture models are [here](https://www.analyticsvidhya.com/blog/2019/10/gaussian-mixture-models-clustering/) and [here](https://scikit-learn.org/stable/modules/mixture.html)

## Useful links

Below are a handful of useful links:

- [HAR data site](https://www.klima.tu-berlin.de/index.php?show=forschung_asien_tibet_har&lan=en)
- Kaggle post on [multi-dimensional clustering](https://www.kaggle.com/ellecf/visualizing-multidimensional-clusters)
- Another kaggle on [multi-dimensional clustering](https://www.kaggle.com/minc33/visualizing-high-dimensional-clusters)
